---
layout: post
title: 隐马尔可夫模型(HMM)和条件随机场(CRF)
published: true
categories: MachineLearning
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

##  1. 隐马尔可夫模型(HMM)
隐马尔可夫模型是一个***序列模型(sequence model)***或者***序列分类器(sequence classifier)***。简单的说，序列模型就是给一个序列里的的每一个单元赋予一个标签或类别。举个栗子，在nlp任务中最常见的pos任务就是对一个由单词组成的语句序列标注词性。例：“HMM is a sequence model.” 对应的序列是“NNP,   VBZ, DT, NN, NN”。像这种序列标注任务在nlp中非常常见，除了POS, 还有NER 和 语音识别等。首先了解下马尔可夫链。
### 1.1 马尔可夫链（Markov Chain）
马尔可夫链可以看作是一个概率图模型，它表示了从一个状态转移到另一个状态的概率。它也可以看作一个一个加权有限自动机模型。因此，马尔可夫模型可以由一个三元组表示：

**状态集合：\\( Q = q_1,q_2, ..., q_n \\)**    

**状态概率转移矩阵：$$A = \begin{pmatrix}a_{01} & a_{02} & ... & a_{0n}\\\ \vdots & \vdots & \ddots & \vdots \\\ a_{n1} & a_{n2} & ... & a_{nn}\end{pmatrix}$$**    

**开始状态和结束状态： \\( q_0, q_F \\)**          


我们在说马尔可夫链是通常是指一阶马尔可夫链，即：当前状态决定了下一个状态，与之前的状态无关。因此马尔可夫链有一个马尔可夫假设：
\\[ P(q_i | q_{i-1}, \dots, q_1) = P(q_i | q_{i-1})\\]
其中，从状态i转移到状态j的概率:\\(P(q_j|q_i) = a_{i,j} \\)

<div style="text-align:center" markdown="1">
![马尔可夫链例子]({{site.baseurl}}/assets/a.png)
</div>
*单词的马尔可夫链*

有了马尔可夫转移概率矩阵，很容易计算出一个序列的概率：比如序列 “<start> snow is white <end>” 的概率为：

 \\[
\begin{eqnarray}
  P(snow,is,white) &=& P(snow|start_0)\dot P(is|snow) \dot P(white|is) \dot P(white|end) \\
  &=& a_{02}\dot a_{21} \dot a_{13} \dot a_{34}
\end{eqnarray}
\\]

  
更多关于马尔可夫链参见：[https://en.wikipedia.org/wiki/Markov_chain](https://en.wikipedia.org/wiki/Markov_chain)

### 1.2 隐马尔可夫模型：
有了马尔可夫链，很容易计算出一个序列的概率。例如序列：“snow is white”。这个能直接得到的序列我们称之为**观察变量（observed variable）**, 除了观察变量还有我们不能直接得到的变量比如，“snow is white”的part of speech tag序列，我们称之为**隐变量(hidden variable)**。 
## 2. 条件随机场（CRF）
